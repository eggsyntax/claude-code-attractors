# ğŸ¯ K-Means Clustering Visualizer

## Overview

A comprehensive, interactive educational tool for understanding the K-Means clustering algorithm. This implementation provides step-by-step visualization, multiple initialization methods, and detailed metrics to help students and practitioners understand how K-means works.

## ğŸŒŸ Features

### Core Algorithm Implementation
- **Complete K-Means Algorithm** with convergence detection
- **K-means++ Initialization** for better starting centroids
- **Step-by-step tracking** of algorithm progress
- **Multiple data generation** modes (random, clustered)
- **WCSS calculation** for cluster quality assessment

### Interactive Visualization
- **Canvas-based visualization** with smooth animations
- **Play/pause/step controls** for detailed exploration
- **Real-time metrics display** (WCSS, iterations, convergence)
- **Customizable parameters** (k, data type, animation speed)
- **Color-coded clusters** with clear centroid markers

### Educational Features
- **Algorithm explanation** with step-by-step breakdown
- **Interactive controls** to experiment with different settings
- **Performance metrics** to understand algorithm behavior
- **Convergence visualization** to see when and why the algorithm stops

## ğŸš€ Quick Start

### Option 1: Open HTML File
Simply open `kmeans-demo.html` in your web browser to start exploring K-means clustering.

### Option 2: Include in Your Project
```html
<!DOCTYPE html>
<html>
<head>
    <title>K-Means Demo</title>
</head>
<body>
    <canvas id="kmeansCanvas"></canvas>
    <div id="kmeansControls"></div>

    <script src="kmeans.js"></script>
    <script src="kmeans-visualization.js"></script>
</body>
</html>
```

### Option 3: Programmatic Usage
```javascript
// Create K-means instance
const kmeans = new KMeansVisualizer();

// Generate data
kmeans.generateClusteredData(3, 20, 400, 300);

// Run algorithm
const steps = kmeans.runKMeans(3, 'kmeans++');

// Access results
console.log('WCSS:', kmeans.calculateWCSS());
console.log('Converged in', steps.length, 'steps');
```

## ğŸ® Using the Interactive Demo

### 1. Generate Data
- **Data Type**: Choose between clustered (realistic) or random data
- **Number of Points**: Adjust from 20 to 100 data points
- **Generate New Data**: Create fresh dataset with current settings

### 2. Configure Algorithm
- **Number of Clusters (k)**: Set from 2 to 8 clusters
- **Initialization Method**: Compare random vs K-means++ initialization
- **Animation Speed**: Control playback speed for learning

### 3. Run and Explore
- **Run K-Means**: Execute the complete algorithm
- **Play/Pause**: Watch automatic step-by-step progression
- **Step Forward/Backward**: Manually control algorithm progression
- **Reset**: Return to the beginning of the algorithm

### 4. Analyze Results
- **WCSS (Within-Cluster Sum of Squares)**: Lower values indicate better clustering
- **Iteration Count**: Number of algorithm iterations until convergence
- **Convergence Status**: Whether the algorithm reached a stable solution

## ğŸ”¬ Educational Concepts

### Algorithm Steps
1. **Initialize Centroids**: Place k centroids in the data space
2. **Assign Points**: Assign each point to its nearest centroid
3. **Update Centroids**: Move centroids to the center of assigned points
4. **Check Convergence**: Repeat until centroids stop moving significantly

### Key Metrics
- **WCSS (Within-Cluster Sum of Squares)**: Î£(distanceÂ²) for all points to their centroids
- **Convergence**: Algorithm stops when centroids move less than tolerance threshold
- **Initialization Impact**: K-means++ typically converges faster than random initialization

### Common Patterns
- **Local Optima**: Different initializations can lead to different final clusterings
- **Cluster Count**: Too few clusters underfit data; too many overfit
- **Data Shape**: K-means works best with spherical, well-separated clusters

## ğŸ“Š Files Structure

```
kmeans-implementation/
â”œâ”€â”€ kmeans.js                 # Core K-means algorithm implementation
â”œâ”€â”€ kmeans-visualization.js   # Interactive visualization component
â”œâ”€â”€ kmeans-demo.html         # Complete educational demo page
â”œâ”€â”€ kmeans-tests.js          # Comprehensive test suite (15 test cases)
â”œâ”€â”€ test-runner.js           # Node.js test execution
â””â”€â”€ KMEANS_README.md         # This documentation
```

## ğŸ§ª Testing

The implementation includes a comprehensive test suite with 15 test cases covering:

- **Basic functionality**: Initialization, data generation, distance calculation
- **Algorithm correctness**: Point assignment, centroid updates, convergence
- **Edge cases**: Empty datasets, single points, more clusters than points
- **Performance**: Large datasets, execution time validation
- **Navigation**: Step-by-step progression controls

### Run Tests
```bash
node test-runner.js
```

Expected output: âœ… All 15 tests should pass

## ğŸ“ Learning Exercises

### Experiment with Different Settings
1. **Vary k (number of clusters)**:
   - Try k=2, k=5, k=8 on the same clustered data
   - Observe how WCSS changes with different k values

2. **Compare initialization methods**:
   - Run the same data with random vs K-means++ initialization
   - Notice differences in convergence speed and final WCSS

3. **Test different data types**:
   - Use random data vs clustered data
   - See when K-means performs well vs poorly

### Questions to Explore
- What happens when k is much larger than the natural number of clusters?
- How does the algorithm handle outlier points?
- Why does K-means++ often converge in fewer iterations?
- Can you identify cases where K-means produces poor results?

## ğŸ”§ Algorithm Configuration

### KMeansVisualizer Options
```javascript
const kmeans = new KMeansVisualizer();

// Configure algorithm parameters
kmeans.maxIterations = 50;    // Maximum iterations before stopping
kmeans.tolerance = 0.001;     // Convergence threshold for centroid movement

// Generate different data types
kmeans.generateRandomData(numPoints, width, height);
kmeans.generateClusteredData(numClusters, pointsPerCluster, width, height);

// Choose initialization method
kmeans.runKMeans(k, 'random');      // Random initialization
kmeans.runKMeans(k, 'kmeans++');    // K-means++ initialization
```

## ğŸŒˆ Visualization Features

### Visual Elements
- **Data Points**: Colored circles representing individual data points
- **Centroids**: Larger circles with crosses, showing cluster centers
- **Connection Lines**: Faded lines from points to their assigned centroids
- **Color Coding**: Each cluster has a distinct color for easy identification

### Animation Controls
- **Smooth transitions** between algorithm steps
- **Adjustable speed** from 0.1s to 2.0s per step
- **Progress indicator** showing current step in algorithm
- **Pause/resume** capability for detailed examination

## ğŸ† Educational Impact

This K-means visualizer transforms abstract algorithmic concepts into concrete, visual experiences:

- **See** how centroids move toward cluster centers
- **Understand** why the algorithm converges
- **Experience** the difference between initialization methods
- **Explore** the impact of parameter choices
- **Discover** when and why K-means works well

Perfect for:
- **Computer Science courses** studying unsupervised learning
- **Data Science education** covering clustering algorithms
- **Self-learners** exploring machine learning concepts
- **Researchers** prototyping clustering approaches

## ğŸš€ Extension Ideas

This implementation provides a solid foundation for extensions:

1. **Additional Algorithms**: K-medoids, hierarchical clustering
2. **Advanced Metrics**: Silhouette analysis, elbow method visualization
3. **3D Visualization**: Extend to three-dimensional clustering
4. **Real Data Integration**: Load and cluster actual datasets
5. **Cluster Validation**: Implement multiple cluster quality metrics

---

**Built with educational excellence in mind** ğŸ“
**Collaborative AI Development** by Alice & Bob Claude Code instances